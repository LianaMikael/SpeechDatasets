# SpeechDatasets 

A collection of large publically available speech datasets for biometric speaker identification, veriffication and diarization, voice cloning, speech enhancement and denoising tasks. Because most audio datasets focus on speech-to-text domain, the motivation was to separate speech datasets for solving text-independent tasks.  

* [VoxCeleb](https://www.robots.ox.ac.uk/~vgg/data/voxceleb/) - audio-visual dataset collected from interviews of famous people; consists of over 7000 speakers of different ethnicities, accents, and ages; 2000 hours of data collected in real-world environmets with backgroud noises. 

* [VoxMovies](https://www.robots.ox.ac.uk/~vgg/data/voxmovies/) - audio dataset with 856 speakers from the VoxCeleb dataset with varying emotion,accents and noise.  

* [VCTK](https://datashare.ed.ac.uk/handle/10283/3443) - 48kHz audio dataset consisting of 110 speakers with different accents reading the same 400 sentences; each sentence is recorded by two different microphones.

* [LibriSpeech](http://www.openslr.org/12) - 1000 hours of 16kHz audio data, contains both clean and noisy examples. 

* [LibriAdapt](https://github.com/akhilmathurs/libriadapt) - dataset constructed from LibriSpeech with demain shifts due to different microphones, speaker accents and acoustic environments. 

* [LibriTTS](https://openslr.org/60/) - dataset constructed from LibriSpeech more suited for speech synthesis, consists of 585 hours of English speech, 24kHz sampling rate, utterances separated when sentences end.

* [TIMIT](https://www.kaggle.com/mfekadu/darpa-timit-acousticphonetic-continuous-speech) - 16kHz audio data of 630 speakers, each reading 10 identical sentences.   

* [M-AILABS](https://www.caito.de/2019/01/the-m-ailabs-speech-dataset/) - 16kHz audio data in 8 languages, contains speaker idenities and genders constructed from audiobooks.

* [DCASE](http://dcase.community/challenge2017/index) - a collection of background sounds that usually occur on the street, in a transport, in an office or at home, such as baby crying, car breaking, people walking, alarms, screams etc. Can be used to train models robust to real-environment background noises. 
